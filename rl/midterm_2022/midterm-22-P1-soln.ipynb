{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.dynamic_programming import V, S, A\n",
    "from rl import dynamic_programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl import markov_process, markov_decision_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Mapping, Iterator, TypeVar, Tuple, Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rl.distribution import Categorical, Choose\n",
    "from rl.iterate import converged, iterate\n",
    "from rl.markov_process import NonTerminal, State\n",
    "from rl.markov_decision_process import (FiniteMarkovDecisionProcess,\n",
    "                                        FiniteMarkovRewardProcess)\n",
    "from rl.policy import FinitePolicy, FiniteDeterministicPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.midterm_2022.priority_q import  PriorityQueue\n",
    "from rl.midterm_2022 import grid_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we will implement the gaps-based value iteration algorithm mentioned in class.\n",
    "\n",
    "The gaps-based iteration algorithm proceeds as follows\n",
    "\n",
    "1. Initialize the value function to zero for all states: $v[s] = 0\\ \\forall s \\in \\mathcal{N}$\n",
    "2. Calculate the gaps for each state: $g[s] = |v[s] - \\max_a \\mathcal{R}(s,a) + \\sum_{s'} \\mathcal{P}(s,a,s') \\cdot v(s')|$\n",
    "3. While there is some gap that exceeds a threshold\n",
    " - Select the state with the  largest gap: $s_{max} = \\arg\\max_{s \\in \\mathcal{N}} g[s]$\n",
    " - Update the value function for $s_{max}$: $v[s_{max}] = \\max_a \\mathcal{R}(s_{max},a) + \\sum_{s'}\\mathcal{P}(s_{max},a,s') \\cdot v(s')$\n",
    " -  Update the gap for $s_{max}$: $g[s_{max}] = 0$\n",
    "4. Return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test your implementation on a grid maze MDP. We have defined this class in \"grid_maze.py\", you should  briefly familiarize yourself with that code. In particular pay attention to the difference in reward functions for the two classes \"GridMazeMDP_Dense\" and \"GridMazeMDP_Sparse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you can use the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_maze = grid_maze.Maze(10, 10)\n",
    "maze_mdp = grid_maze.GridMazeMDP_Sparse(underlying_maze, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can visualize the maze if you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "|*          | |     |\n",
      "| + + +-+-+ + +-+ +-+\n",
      "| | |     | | |   | |\n",
      "| +-+-+-+-+-+ + +-+ +\n",
      "|     |   | | |   | |\n",
      "| +-+ + +-+ + + +-+ +\n",
      "|   |       | | |   |\n",
      "|-+ +-+ +-+-+ + + +-+\n",
      "|     |             |\n",
      "| + +-+ + +-+ +-+ + +\n",
      "| | |   | | |   | | |\n",
      "|-+ + + +-+ + +-+-+-+\n",
      "|   | | | | |   | | |\n",
      "|-+-+ +-+ + +-+ + + +\n",
      "| | |       | |   | |\n",
      "| + + + +-+-+ +-+-+ +\n",
      "| |   |   |     |   |\n",
      "| +-+ +-+-+-+ +-+ + +\n",
      "|                 | |\n",
      "|-+-+-+-+-+-+-+-+-+-+\n"
     ]
    }
   ],
   "source": [
    "print(maze_mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also visualize a policy on the mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "|* < < < < <|v|> v <|\n",
      "| + + +-+-+ + +-+ +-+\n",
      "|^|^|^ < <|^|v|v <|v|\n",
      "| +-+-+-+-+-+ + +-+ +\n",
      "|^ < <|v <|v|v|v <|v|\n",
      "| +-+ + +-+ + + +-+ +\n",
      "|^ <|^ < < <|v|v|v <|\n",
      "|-+ +-+ +-+-+ + + +-+\n",
      "|> ^ <|^ < < < < < <|\n",
      "| + +-+ + +-+ +-+ + +\n",
      "|^|^|> ^|^|v|^ <|^|^|\n",
      "|-+ + + +-+ + +-+-+-+\n",
      "|> ^|^|^|v|v|^ <|v|v|\n",
      "|-+-+ +-+ + +-+ + + +\n",
      "|v|v|^ < < <|v|^ <|v|\n",
      "| + + + +-+-+ +-+-+ +\n",
      "|v|> ^|^ <|> v <|v <|\n",
      "| +-+ +-+-+-+ +-+ + +\n",
      "|> > ^ < < < < < <|^|\n",
      "|-+-+-+-+-+-+-+-+-+-+\n"
     ]
    }
   ],
   "source": [
    "v2_res = dynamic_programming.value_iteration_result(maze_mdp, 0.9)\n",
    "print(maze_mdp.print_policy(v2_res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to make use of the PriorityQueue class in your implementation. A PriorityQueue is an ordered queue which supports the following operations\n",
    "1. isEmpty(self): check if the queue is empty   \n",
    "2. contains(self, element): check if the queue contains an element\n",
    "3. peek(self): peek at the highest priority element in the queue    \n",
    "4. pop(self): remove and return the highest priority element in the queue    \n",
    "5. insert(self, element, priority): insert an element into the queue with given priority\n",
    "6. update(self, element, new_priority): update the priority of an element in the queue\n",
    "7. delete(self, element): delete an element from the queue\n",
    "\n",
    "Below are some examples of using the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : the queue is empty\n",
      "False : the queue is not empty\n",
      "True : the queue contains a\n",
      "False : the queue does not contain a\n",
      "(1, 'a') : a is the first element in the queue\n",
      "True : the queue now contains b\n",
      "(0, 'b') : b is now at the front of the queue\n",
      "b : we removed b from the queue\n",
      "False : the queue still nonempty\n",
      "True : the queue still contains a\n",
      "False : the queue does not contain b anymore\n",
      "(1, 'a') : a is at the front of the queue\n",
      "(1, 'a') : a is still at the front of the queue\n",
      "(5, 'c') : after updating a is no longer at the front of the queue\n"
     ]
    }
   ],
   "source": [
    "q: PriorityQueue = PriorityQueue()\n",
    "print(q.isEmpty(), ':', \"the queue is empty\")\n",
    "q.insert(\"a\", 1)\n",
    "print(q.isEmpty(), ':',  \"the queue is not empty\")\n",
    "print(q.contains(\"a\"), ':',  \"the queue contains a\")\n",
    "print(q.contains(\"b\"), ':',  \"the queue does not contain a\")\n",
    "print(q.peek(), ':',  \"a is the first element in the queue\")\n",
    "q.insert(\"b\", 0)\n",
    "print(q.contains(\"b\"), ':',  \"the queue now contains b\")\n",
    "print(q.peek(), ':',  \"b is now at the front of the queue\")\n",
    "x = q.pop()\n",
    "print(x, ':',  \"we removed b from the queue\")\n",
    "print(q.isEmpty(), ':',  \"the queue still nonempty\")\n",
    "print(q.contains(\"a\"), ':',  \"the queue still contains a\")\n",
    "print(q.contains(\"b\"), ':',  \"the queue does not contain b anymore\")\n",
    "print(q.peek(), ':',  \"a is at the front of the queue\")\n",
    "q.insert(\"c\", 5)\n",
    "print(q.peek(), ':',  \"a is still at the front of the queue\")\n",
    "q.update(\"a\", 6)\n",
    "print(q.peek(), ':',  \"after updating a is no longer at the front of the queue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.insert(NonTerminal('d'),3)\n",
    "\n",
    "q.insert(NonTerminal('e'),3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def invert_transition_map(mdp: markov_decision_process.FiniteMarkovDecisionProcess[S, A]) ->\\\n",
    "            Mapping[S, Iterable[S]]:\n",
    "    '''\n",
    "    YOUR CODE HERE\n",
    "    Implement the invert_transition_map method\n",
    "    '''\n",
    "    inverted_mapping = defaultdict(list)\n",
    "    transition_mapping = mdp.mapping\n",
    "    for source in transition_mapping:\n",
    "        for a in transition_mapping[source]:\n",
    "            for s2 in transition_mapping[source][a]:\n",
    "                inverted_mapping[markov_process.NonTerminal(s2[0][0].state)].append(source)\n",
    "    '''END YOUR CODE'''\n",
    "    return inverted_mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaps_value_iteration(\n",
    "    mdp: markov_decision_process.FiniteMarkovDecisionProcess[S, A],\n",
    "    gamma: float, \n",
    "    gaps: PriorityQueue) -> Iterator[V[S]]:\n",
    "    '''\n",
    "    Calculate the value function (V*) of the given MDP by applying the\n",
    "    update function repeatedly until the values converge.\n",
    "\n",
    "    '''\n",
    "    dependency_map = invert_transition_map(mdp)\n",
    "    v_0: V[S] = {s: 0.0 for s in mdp.non_terminal_states}\n",
    "    \n",
    "        \n",
    "    def update(v: V[S]) -> V[S]:\n",
    "        '''\n",
    "        YOUR CODE HERE\n",
    "        perform a single update to v for the state with the largest gap\n",
    "        update the gaps for any dependent states\n",
    "        '''\n",
    "        to_update = gaps.pop()\n",
    "\n",
    "        v[to_update] = max(mdp.mapping[to_update][a].expectation(\n",
    "                lambda s_r: s_r[1] + gamma * dynamic_programming.extended_vf(v, s_r[0])\n",
    "            ) for a in mdp.actions(to_update))\n",
    "        for s in dependency_map[to_update]:\n",
    "            gap = np.abs(v[s] - max(mdp.mapping[s][a].expectation(\n",
    "                lambda s_r: s_r[1] + gamma * dynamic_programming.extended_vf(v, s_r[0])\n",
    "            ) for a in mdp.actions(s)))\n",
    "            if gap > 0:\n",
    "                if gaps.contains(s) :\n",
    "                    gaps.update(s, -gap)\n",
    "                else:\n",
    "                    gaps.insert(s, -gap)\n",
    "                    \n",
    "        '''END YOUR CODE'''\n",
    "        return v\n",
    "\n",
    "    \n",
    "    return iterate(update, v_0)\n",
    "\n",
    "\n",
    "def gaps_value_iteration_result(\n",
    "    mdp: FiniteMarkovDecisionProcess[S, A],\n",
    "    gamma: float\n",
    ") -> Tuple[V[S], FiniteDeterministicPolicy[S, A]]:\n",
    "    \n",
    "    gaps = PriorityQueue()\n",
    "    \n",
    "    '''\n",
    "    YOUR CODE HERE\n",
    "    instantiate the value function and populate the gaps\n",
    "    ''' \n",
    "    v_0: V[S] = {s: 0.0 for s in mdp.non_terminal_states}\n",
    "    for s in mdp.non_terminal_states:\n",
    "        gap = np.abs(max(mdp.mapping[s][a].expectation(\n",
    "                lambda s_r: s_r[1] + gamma * dynamic_programming.extended_vf(v_0, s_r[0])\n",
    "            ) for a in mdp.actions(s)))\n",
    "        if gap > 0:\n",
    "            gaps.insert(s, -gap)\n",
    "    ''' END YOUR CODE ''' \n",
    "    \n",
    "    def criterion(x,y):\n",
    "        '''\n",
    "        YOUR CODE HERE\n",
    "        implement the criterion for convergence of the value function \n",
    "        ''' \n",
    "        if gaps.isEmpty():\n",
    "            return True\n",
    "        return np.abs(gaps.peek()[0]) <= 1e-10\n",
    "        ''' END YOUR CODE ''' \n",
    "        \n",
    "    opt_vf: V[S] = converged(\n",
    "        gaps_value_iteration(mdp, gamma, gaps),\n",
    "        done=criterion \n",
    "    )\n",
    "        \n",
    "    opt_policy: markov_decision_process.FiniteDeterministicPolicy[S, A] = dynamic_programming.greedy_policy_from_vf(\n",
    "        mdp,\n",
    "        opt_vf,\n",
    "        gamma\n",
    "    )\n",
    "\n",
    "    return opt_vf, opt_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not change the code below here, just run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the VF for a maze with sparse rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_maze = grid_maze.Maze(50, 50)\n",
    "maze_mdp = grid_maze.GridMazeMDP_Sparse(underlying_maze, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### printing the runtime for the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17281818389892578\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "v1_res = gaps_value_iteration_result(maze_mdp, 0.9)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.571290969848633\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "v2_res = dynamic_programming.value_iteration_result(maze_mdp, 0.9)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confirming that the value functions are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert v1_res[1] == v2_res[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the VF for a maze with dense rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_mdp = grid_maze.GridMazeMDP_Dense(underlying_maze, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### printing the runtime for the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.129434108734131\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "v1_res = gaps_value_iteration_result(maze_mdp, 1)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8715617656707764\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "v2_res = dynamic_programming.value_iteration_result(maze_mdp, 1)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confirming that the value functions are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert v1_res[1] == v2_res[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
